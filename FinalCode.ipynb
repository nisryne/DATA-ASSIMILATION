{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdFF3gyuqMOa",
        "outputId": "4bc1b6b7-0072-46c5-a1a0-3d5858d28f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "77/77 [==============================] - 2s 6ms/step - loss: 1.5490 - val_loss: 1.2262\n",
            "Epoch 2/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 1.0881 - val_loss: 1.0034\n",
            "Epoch 3/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.8986 - val_loss: 0.8300\n",
            "Epoch 4/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.7563 - val_loss: 0.6856\n",
            "Epoch 5/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6306 - val_loss: 0.5670\n",
            "Epoch 6/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5362 - val_loss: 0.4800\n",
            "Epoch 7/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4528 - val_loss: 0.4093\n",
            "Epoch 8/100\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.3953 - val_loss: 0.3579\n",
            "Epoch 9/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3404 - val_loss: 0.3150\n",
            "Epoch 10/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.3023 - val_loss: 0.2853\n",
            "Epoch 11/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.2785 - val_loss: 0.2783\n",
            "Epoch 12/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.2562 - val_loss: 0.2620\n",
            "Epoch 13/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.2392 - val_loss: 0.2223\n",
            "Epoch 14/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.2212 - val_loss: 0.2083\n",
            "Epoch 15/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.2100 - val_loss: 0.2006\n",
            "Epoch 16/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1998 - val_loss: 0.1972\n",
            "Epoch 17/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1919 - val_loss: 0.1711\n",
            "Epoch 18/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1982 - val_loss: 0.1545\n",
            "Epoch 19/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1839 - val_loss: 0.1528\n",
            "Epoch 20/100\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1837 - val_loss: 0.1421\n",
            "Epoch 21/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1734 - val_loss: 0.1486\n",
            "Epoch 22/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1712 - val_loss: 0.1511\n",
            "Epoch 23/100\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1660 - val_loss: 0.1343\n",
            "Epoch 24/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1681 - val_loss: 0.1330\n",
            "Epoch 25/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1684 - val_loss: 0.1308\n",
            "Epoch 26/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1649 - val_loss: 0.1321\n",
            "Epoch 27/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1680 - val_loss: 0.1289\n",
            "Epoch 28/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1600 - val_loss: 0.1246\n",
            "Epoch 29/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1516 - val_loss: 0.1213\n",
            "Epoch 30/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.1258\n",
            "Epoch 31/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1567 - val_loss: 0.1175\n",
            "Epoch 32/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1559 - val_loss: 0.1207\n",
            "Epoch 33/100\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1572 - val_loss: 0.1209\n",
            "Epoch 34/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1557 - val_loss: 0.1183\n",
            "Epoch 35/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1476 - val_loss: 0.1164\n",
            "Epoch 36/100\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1467 - val_loss: 0.1191\n",
            "Epoch 37/100\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1494 - val_loss: 0.1135\n",
            "Epoch 38/100\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1501 - val_loss: 0.1152\n",
            "Epoch 39/100\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1459 - val_loss: 0.1146\n",
            "Epoch 40/100\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.1444 - val_loss: 0.1220\n",
            "Epoch 41/100\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1444 - val_loss: 0.1140\n",
            "Epoch 42/100\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1449 - val_loss: 0.1237\n",
            "Epoch 43/100\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1446 - val_loss: 0.1125\n",
            "Epoch 44/100\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1411 - val_loss: 0.1092\n",
            "Epoch 45/100\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1419 - val_loss: 0.1167\n",
            "Epoch 46/100\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.1427 - val_loss: 0.1145\n",
            "Epoch 47/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1426 - val_loss: 0.1110\n",
            "Epoch 48/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1452 - val_loss: 0.1153\n",
            "Epoch 49/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1414 - val_loss: 0.1099\n",
            "Epoch 50/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1440 - val_loss: 0.1062\n",
            "Epoch 51/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1360 - val_loss: 0.1085\n",
            "Epoch 52/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1349 - val_loss: 0.1075\n",
            "Epoch 53/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1365 - val_loss: 0.1086\n",
            "Epoch 54/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1379 - val_loss: 0.1082\n",
            "Epoch 55/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1379 - val_loss: 0.1046\n",
            "Epoch 56/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.1092\n",
            "Epoch 57/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1403 - val_loss: 0.1075\n",
            "Epoch 58/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1373 - val_loss: 0.1031\n",
            "Epoch 59/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1356 - val_loss: 0.1021\n",
            "Epoch 60/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1395 - val_loss: 0.1039\n",
            "Epoch 61/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1463 - val_loss: 0.1029\n",
            "Epoch 62/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1328 - val_loss: 0.1066\n",
            "Epoch 63/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1365 - val_loss: 0.1047\n",
            "Epoch 64/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1352 - val_loss: 0.1076\n",
            "Epoch 65/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1419 - val_loss: 0.1055\n",
            "Epoch 66/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1399 - val_loss: 0.1034\n",
            "Epoch 67/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1350 - val_loss: 0.1063\n",
            "Epoch 68/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1388 - val_loss: 0.1046\n",
            "Epoch 69/100\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.1379 - val_loss: 0.1054\n",
            "24/24 [==============================] - 0s 2ms/step\n",
            "Average R-squared: 0.9343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/scalerY_23.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib  # Import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_excel('/content/dataset.xlsx', engine='openpyxl')\n",
        "\n",
        "# Define input and output columns\n",
        "input_columns = [\n",
        "    'Net Volume', 'Pulp Area', 'Froth surface area', 'Froth thickness', 'Air Flow rate',\n",
        "    'R_inf Ccp', 'R_inf Gn', 'R_inf Po', 'R_inf Sp', 'k_max Ccp', 'k_max Gn', 'k_maxPo',\n",
        "    'k_max Sp', 'Entrainement Savassi parameters', 'Total Solids Flow_Feed',\n",
        "    'Total Liquid Flow_Feed', 'Pulp Volumetric Flow_Feed', 'Solids SG_Feed', 'Pulp SG_Feed',\n",
        "    'Solids Fraction_Feed', 'Cu_Feed', 'Fe_Feed', 'Pb_Feed', 'Zn_Feed'\n",
        "]\n",
        "\n",
        "output_columns = [\n",
        "    'Air Efficiency', 'Flotation Rate: Cell 1', 'Entrainment: Cell 1',\n",
        "    'Total Solids Flow_Concentrate', 'Total Liquid Flow_Concentrate',\n",
        "    'Pulp Volumetric Flow_Concentrate', 'Solids SG_Concentrate', 'Pulp SG_Concentrate',\n",
        "    'Solids Fraction_Concentrate', 'Total Solids Flow_Tailings', 'Total Liquid Flow_Tailings',\n",
        "    'Pulp Volumetric Flow_Tailings', 'Solids SG_Tailings', 'Pulp SG_Tailings',\n",
        "    'Solids Fraction_Tailings', 'Cu_Tails', 'Fe_Tails', 'Pb_Tails', 'Zn_Tails',\n",
        "    'Cu_Concentrate', 'Fe_Concentrate', 'Pb_Concentrate', 'Zn_Concentrate'\n",
        "]\n",
        "\n",
        "# Standard Scaling Features\n",
        "scalerX = StandardScaler()\n",
        "scaled_input = scalerX.fit_transform(data[input_columns])\n",
        "\n",
        "# Scaling output data\n",
        "scalerY = StandardScaler()\n",
        "scaled_output = scalerY.fit_transform(data[output_columns])\n",
        "\n",
        "# Splitting data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_input, scaled_output, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Definition using the Best Parameters\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l1_l2(l1=0.001, l2=0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)))\n",
        "model.add(Dense(len(output_columns)))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_rescaled = scalerY.inverse_transform(y_pred)\n",
        "y_test_rescaled = scalerY.inverse_transform(y_test)\n",
        "\n",
        "# Calculate R-squared for each output and the average\n",
        "r2_scores = [r2_score(y_test_rescaled[:, i], y_pred_rescaled[:, i]) for i in range(y_test_rescaled.shape[1])]\n",
        "average_r2 = sum(r2_scores) / len(r2_scores)\n",
        "print(f'Average R-squared: {average_r2:.4f}')\n",
        "\n",
        "# Save the model and scalers\n",
        "model.save('/content/final_model.h5')\n",
        "joblib.dump(scalerX, '/content/scalerX_24.joblib')\n",
        "joblib.dump(scalerY, '/content/scalerY_23.joblib')\n"
      ]
    }
  ]
}